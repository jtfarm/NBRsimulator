{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of NBR07 with measured parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResSimulator import NBResonator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrappingSimulator import QPtrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = r\"G:\\Shared drives\\LFL\\Simulations\\James\\NBR07\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definition of parameters used in QP trapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 0.05 # seconds to record data\n",
    "sampleRate = 300e6\n",
    "N = int(duration*sampleRate)\n",
    "tauTrap = 40e-6\n",
    "tauRelease = 10e-6\n",
    "tauCommon = 1e-4\n",
    "tauRare = 7e-1\n",
    "tauRecomb = 1.5e-4\n",
    "phi = 0.45\n",
    "Lj = 20.8475e-12 # squid inductance at zero phase bias\n",
    "# Lj = 31.7299e-12\n",
    "args = {'N':N,'Lj':Lj,'tauTrap':tauTrap,'tauRelease':tauRelease,'tauCommon':tauCommon,'tauRare':tauRare,\n",
    "        'tauRecomb':tauRecomb,'sampleRate':sampleRate,'phi':phi,'Delta':2.72370016e-23,'T':0.010}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trapper = QPtrapper(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have the trapping events, let's generate the resonator response. define some more parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1.82897e-9\n",
    "C = 0.739929e-12\n",
    "# L = 2.7837e-9\n",
    "# C = 0.486155e-12\n",
    "Qi = 53000\n",
    "Qe = 25000\n",
    "photonRO = 45\n",
    "photonNoise = 3\n",
    "delKappa = -0.5\n",
    "\n",
    "resArgs = {'L':L,'C':C,'photonRO':photonRO,'photonNoise':photonNoise,'Qi':Qi,'Qe':Qe,'sampleRate':sampleRate,'delKappa':delKappa}\n",
    "\n",
    "res = NBResonator(trapper,**resArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fd': 4277461605.8818517,\n",
       " 'f0': 4277587512.2312684,\n",
       " 'Qt': 16987.17948717949,\n",
       " 'Qi': 53000,\n",
       " 'Qe': 25000,\n",
       " 'N': 15000000,\n",
       " 'q': 0.02241579930274248,\n",
       " 'photonRO': 45,\n",
       " 'sampleRate': 300000000.0,\n",
       " 'kappa': 1582185.8494702321,\n",
       " 'fwhm': 251812.6988332369,\n",
       " 'diameter': 1.358974358974359,\n",
       " 'freq_shift': 192235.2624739662,\n",
       " 'SNR': 0.024948213529382368,\n",
       " 'SNRdB': -16.029605475199105,\n",
       " 'sigma': 6.3311160427631625}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.dParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start some analysis with integration for desired SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "integrate for 0.2809053339677251 us for RF power SNR=5\n",
      "integrate for 2.809053339677251 us for RF power SNR=50\n"
     ]
    }
   ],
   "source": [
    "from scipy.constants import pi\n",
    "from scipy.signal import windows, convolve\n",
    "avgTime5 = 4*res.dParams['Qt']*5/(res.dParams['photonRO']*2*pi*res.dParams['f0'])\n",
    "avgTime10 = 4*res.dParams['Qt']*10/(res.dParams['photonRO']*2*pi*res.dParams['f0'])\n",
    "avgTime25 = 4*res.dParams['Qt']*25/(res.dParams['photonRO']*2*pi*res.dParams['f0'])\n",
    "avgTime50 = 4*res.dParams['Qt']*50/(res.dParams['photonRO']*2*pi*res.dParams['f0'])\n",
    "print('integrate for {} us for RF power SNR=5'.format(avgTime5*1e6))\n",
    "print('integrate for {} us for RF power SNR=50'.format(avgTime50*1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform convolution for 5 microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dae78c76845a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# rhann = convolve(res.signal.real,window,mode='same')/sum(window)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# ihann = convolve(res.signal.imag,window,mode='same')/sum(window)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrhann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mihann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnAvg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "nAvg = int(max(2e-6*res.dParams['sampleRate'],1))\n",
    "window = windows.hann(nAvg)\n",
    "# rhann = convolve(res.signal.real,window,mode='same')/sum(window)\n",
    "# ihann = convolve(res.signal.imag,window,mode='same')/sum(window)\n",
    "rhann = np.mean(res.signal.real[:len(res.signal)//(nAvg)*nAvg].reshape((len(res.signal)//(nAvg),nAvg)),axis=1)\n",
    "ihann = np.mean(res.signal.imag[:len(res.signal)//(nAvg)*nAvg].reshape((len(res.signal)//(nAvg),nAvg)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a segment as time series for visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "time = np.arange(res.dParams['N'])/res.dParams['sampleRate']\n",
    "time = np.mean(time[:len(res.signal)//(nAvg)*nAvg].reshape((len(res.signal)//(nAvg),nAvg)),axis=1)\n",
    "\n",
    "h = plt.subplot()\n",
    "pltmask = np.logical_and(time > 3e-3, time < 3.5e-3)\n",
    "plttime = time[pltmask]*1e6 - 3000\n",
    "h.plot(plttime,rhann[pltmask],label='I(t)')\n",
    "h.plot(plttime,ihann[pltmask],color='yellow',label='Q(t)')\n",
    "h.set_xlabel('Time [$\\mu$s]',fontsize = 16)\n",
    "h.set_ylabel('V / |V|',fontsize = 14)\n",
    "h.tick_params(labelsize=12)\n",
    "h.legend(fontsize=12)\n",
    "plt.savefig(savepath+r'NBR07_noisySignal_2microsecond.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot complex histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.subplot()\n",
    "hs = plt.hist2d(rhann,ihann,bins=(80,80),norm=LogNorm(),cmap=plt.get_cmap('Greys'))\n",
    "hb = plt.colorbar(hs[-1], shrink=0.9, extend='both')\n",
    "h.set_aspect('equal')\n",
    "h.grid()\n",
    "h.set_xlabel('I',fontsize=16)\n",
    "h.set_ylabel('Q',fontsize=14)\n",
    "h.tick_params(labelsize=12)\n",
    "plt.savefig(savepath+r'NBR07_hist.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,sharex=True,figsize=[9,6],constrained_layout=True)\n",
    "# ax[0].plot(time*1e3,np.arctan((ihann/rhann)))\n",
    "# ax[0].set_ylabel('phase [rad]')\n",
    "# ax[1].plot(time*1e3,np.sqrt(rhann**2 + ihann**2))\n",
    "# ax[1].set_ylabel('Magnitude')\n",
    "# ax[1].set_xlabel('time [ms]')\n",
    "ax[0].plot(plttime,rhann[pltmask], label='I')\n",
    "ax[0].plot(plttime,ihann[pltmask], color='yellow',label = 'Q')\n",
    "ax[0].set_title('Simulated - 2 $\\mu$s integration')\n",
    "ax[0].set_ylabel('Quadratures [mV]')\n",
    "ax[0].legend()\n",
    "ax[1].plot(plttime,np.abs(rhann[pltmask] + 1j*ihann[pltmask]))\n",
    "ax[1].set_ylabel('Magnitude [mV]')\n",
    "ax[1].set_xlabel('Time [$\\mu$s]')\n",
    "\n",
    "\n",
    "plt.savefig(savepath+r'NBR07_mag_phase.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this level of SNR sufficient for machine learning alg to detect occupation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgTime25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're already averaging for 18.6 microseconds and assuming quantum limited noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('avg # trapped = {:.4}'.format(np.mean(trapper.nTrapped)))\n",
    "print('max # = {}'.format(np.max(trapper.nTrapped)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use scikit package for expectation-maximization algorithm to fit gaussian mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial guess at mode locations, based on looking at complex hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_guess = np.array([[-0.5,0.4,-0.6,-1],[0.75,-0.25,-0.5,0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run the ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(n_components = len(means_guess),means_init=means_guess)\n",
    "estimator.fit(np.array([rhann,ihann]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.means_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the pretty plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "colors = ['red','orange','yellow','green']\n",
    "def make_ellipses(gmm,ax):\n",
    "    for n, color in enumerate(colors):\n",
    "        # get the covariance matrix for the mode associated with n trapped QPs\n",
    "        covariances = gmm.covariances_[n][:2,:2]\n",
    "        # v are the eigenvalues of covariance matrix, aka the variances along major and minor axis of ellipse. w are the eigenvectors. Order is smallest to v to largest v\n",
    "        v, w = np.linalg.eigh(covariances)\n",
    "        # normalize the eigenvector associated with the smallest variance, i.e., the variance along the minor axis.\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        # get the angle from +x axis to minor axis of ellipse\n",
    "        angle = 180*np.arctan2(u[1],u[0])/np.pi\n",
    "        # v is now the diameter of the ellipse in minor, major order. It is equal to 2 std deviations.\n",
    "        v = 2. *np.sqrt(v)\n",
    "        # make the ellipse for mode n. Centered at mean with major and minor radius of 1 std deviation. and rotated to align to the data.\n",
    "        ell = Ellipse(gmm.means_[n,:2],v[0],v[1],180+angle,color=color)\n",
    "        # now we just add the ellipses to the plot. Note that these ellipses shade the area in which all data points are within 1 std deviation of the mean.\n",
    "        ell.set_clip_box(ax.bbox)\n",
    "        ell.set_alpha(0.9)\n",
    "        ax.add_artist(ell)\n",
    "        ax.set_aspect('equal','datalim')\n",
    "\n",
    "h = plt.subplot()\n",
    "make_ellipses(estimator,h)\n",
    "hs = plt.hist2d(rhann,ihann,bins=(80,80),norm=LogNorm(),cmap=plt.get_cmap('Greys'))\n",
    "hb = plt.colorbar(hs[-1], shrink=0.9, extend='both')\n",
    "h.set_xlabel('I',fontsize=16)\n",
    "h.set_ylabel('Q',fontsize=14)\n",
    "h.tick_params(labelsize=12)\n",
    "plt.savefig(savepath+r'NBR07_hist_modes.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the estimator accurately predict the trap state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEst = np.empty(res.dParams['N'],dtype=int)\n",
    "nEst[:] = estimator.predict(np.transpose((rhann,ihann)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the avg number of trapped QPs compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('simulated avg # = {:.4}'.format(np.mean(trapper.nTrapped)))\n",
    "print('estimator avg # = {:.4}'.format(np.mean(nEst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a good agreement. How does it look when we plot two segments together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.subplot()\n",
    "h.plot(time[100000:500000]*1e6,trapper.nTrapped[100000:500000],'r',alpha=0.9,label='Simulation',lw=0.8)\n",
    "h.plot(time[100000:500000]*1e6,nEst[100000:500000],'b',alpha=0.9,label='Estimated',lw=0.8)\n",
    "h.set_xlabel('Time [$\\mu$s]',fontsize = 16)\n",
    "h.set_ylabel('Number of trapped QPs',fontsize = 14)\n",
    "plt.yticks([0,1,2,3,4])\n",
    "h.tick_params(labelsize=12)\n",
    "h.legend(fontsize=14)\n",
    "plt.savefig(savepath+r'NBR07_estimationComparison.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like the estimator is switching far too often. perhaps a different averaging method will work better (instead of convolution with Hann window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's quantitatively look at the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errTrap = np.diff((nEst,trapper.nTrapped),axis=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### errTrap is the difference, errTrap[i] = nTrapped[i] - nEst[i]. It should be positive when we underestimate and negative when we overestimate. The mean should approach 0 for large dataset unless we are somehow more prone to over or under estimating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(errTrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ok, now let's quantify the error. The root mean square of the difference should tell us what percent of the time we're wrong about the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(errTrap**2))*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Being wrong 40% of the time isn't exactly something to brag about.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually, the above isn't really how often we're wrong, but overestimates this since errTrap is the difference and can be greater than zero. what we need is an array that is 0 when the estimator is right and 1 when it is wrong. mean of this is the actual percent of time we're wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estFalse = np.array(np.abs(errTrap) > 0,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(estFalse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for exponential window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAvg = int(max(5e-6*res.dParams['sampleRate'],1))\n",
    "window = windows.exponential(nAvg,tau=-(nAvg-1)/np.log(0.00001))\n",
    "rhann = convolve(res.signal.real,window,mode='same')/sum(window)\n",
    "ihann = convolve(res.signal.imag,window,mode='same')/sum(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "time = np.arange(res.dParams['N'])/res.dParams['sampleRate']\n",
    "\n",
    "h = plt.subplot()\n",
    "h.plot(time[150000:250000]*1e6,rhann[150000:250000],'r',alpha=0.9,label='I(t)')\n",
    "h.plot(time[150000:250000]*1e6,ihann[150000:250000],'b',alpha=0.9,label='Q(t)')\n",
    "h.set_xlabel('Time [$\\mu$s]',fontsize = 16)\n",
    "h.set_ylabel('V / |V|',fontsize = 14)\n",
    "h.tick_params(labelsize=12)\n",
    "h.legend(fontsize=12)\n",
    "plt.savefig(savepath+r'NBR07_noisySignal_SNR25_exp.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.subplot()\n",
    "hs = plt.hist2d(rhann,ihann,bins=(80,80),norm=LogNorm(),cmap=plt.get_cmap('Greys'))\n",
    "hb = plt.colorbar(hs[-1], shrink=0.9, extend='both')\n",
    "h.set_aspect('equal')\n",
    "h.grid()\n",
    "h.set_xlabel('I',fontsize=16)\n",
    "h.set_ylabel('Q',fontsize=14)\n",
    "h.tick_params(labelsize=12)\n",
    "plt.savefig(savepath+r'NBR07_hist_exp.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,ax = plt.subplots(2,1,sharex=True)\n",
    "ax[0].plot(time*1e3,np.arctan((ihann/rhann)))\n",
    "ax[0].set_ylabel('phase [rad]')\n",
    "ax[1].plot(time*1e3,np.sqrt(rhann**2 + ihann**2))\n",
    "ax[1].set_ylabel('Magnitude')\n",
    "ax[1].set_xlabel('time [ms]')\n",
    "plt.savefig(savepath+r'NBR07_mag_phase_exp.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(n_components = len(means_guess),means_init=means_guess)\n",
    "estimator.fit(np.array([rhann,ihann]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GaussianMixture(n_components = len(means_guess),means_init=means_guess)\n",
    "estimator.fit(np.array([rhann,ihann]).T)\n",
    "\n",
    "### Did it work?\n",
    "\n",
    "estimator.converged_\n",
    "\n",
    "estimator.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "colors = ['red','orange','yellow','green']\n",
    "def make_ellipses(gmm,ax):\n",
    "    for n, color in enumerate(colors):\n",
    "        # get the covariance matrix for the mode associated with n trapped QPs\n",
    "        covariances = gmm.covariances_[n][:2,:2]\n",
    "        # v are the eigenvalues of covariance matrix, aka the variances along major and minor axis of ellipse. w are the eigenvectors. Order is smallest to v to largest v\n",
    "        v, w = np.linalg.eigh(covariances)\n",
    "        # normalize the eigenvector associated with the smallest variance, i.e., the variance along the minor axis.\n",
    "        u = w[0] / np.linalg.norm(w[0])\n",
    "        # get the angle from +x axis to minor axis of ellipse\n",
    "        angle = 180*np.arctan2(u[1],u[0])/np.pi\n",
    "        # v is now the diameter of the ellipse in minor, major order. It is equal to 2 std deviations.\n",
    "        v = 2. *np.sqrt(v)\n",
    "        # make the ellipse for mode n. Centered at mean with major and minor radius of 1 std deviation. and rotated to align to the data.\n",
    "        ell = Ellipse(gmm.means_[n,:2],v[0],v[1],180+angle,color=color)\n",
    "        # now we just add the ellipses to the plot. Note that these ellipses shade the area in which all data points are within 1 std deviation of the mean.\n",
    "        ell.set_clip_box(ax.bbox)\n",
    "        ell.set_alpha(0.9)\n",
    "        ax.add_artist(ell)\n",
    "        ax.set_aspect('equal','datalim')\n",
    "\n",
    "h = plt.subplot()\n",
    "make_ellipses(estimator,h)\n",
    "hs = plt.hist2d(rhann,ihann,bins=(80,80),norm=LogNorm(),cmap=plt.get_cmap('Greys'))\n",
    "hb = plt.colorbar(hs[-1], shrink=0.9, extend='both')\n",
    "h.set_xlabel('I',fontsize=16)\n",
    "h.set_ylabel('Q',fontsize=14)\n",
    "h.tick_params(labelsize=12)\n",
    "plt.savefig(savepath+r'NBR07_hist_modes_exp.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEst = np.empty(res.dParams['N'],dtype=int)\n",
    "nEst[:] = estimator.predict(np.transpose((rhann,ihann)))\n",
    "\n",
    "### How do the avg number of trapped QPs compare?\n",
    "\n",
    "print('simulated avg # = {:.4}'.format(np.mean(trapper.nTrapped)))\n",
    "print('estimator avg # = {:.4}'.format(np.mean(nEst)))\n",
    "\n",
    "### That's a good agreement. How does it look when we plot two segments together?\n",
    "\n",
    "h = plt.subplot()\n",
    "h.plot(time[100000:500000]*1e6,trapper.nTrapped[100000:500000],'r',alpha=0.9,label='Simulation',lw=0.8)\n",
    "h.plot(time[100000:500000]*1e6,nEst[100000:500000],'b',alpha=0.9,label='Estimated',lw=0.8)\n",
    "h.set_xlabel('Time [$\\mu$s]',fontsize = 16)\n",
    "h.set_ylabel('Number of trapped QPs',fontsize = 14)\n",
    "plt.yticks([0,1,2,3,4])\n",
    "h.tick_params(labelsize=12)\n",
    "h.legend(fontsize=14)\n",
    "plt.savefig(savepath+r'NBR07_estimationComparison_exp.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_n_phi(phi,n, L = 1.82897e-9,C = 0.739929e-12,Lj = 20.8475e-12):\n",
    "    de = np.pi*phi\n",
    "    Ljphi = Lj/(1-np.sin(de/2)*np.arctanh(np.sin(de/2)))\n",
    "    q = Ljphi/(L+Ljphi)\n",
    "    Delta=2.72370016e-23\n",
    "    rphi0 = (2.06783383*1e-15)/(2*np.pi)\n",
    "    f0 = 1/(2*np.pi*np.sqrt((L+Ljphi)*C))\n",
    "    alpha = Delta/(2*(rphi0**2))\n",
    "    L1 = alpha*(np.cos(de)/np.sqrt(1-np.sin(de/2)**2) + (np.sin(de)**2)/(4*(np.sqrt(1-np.sin(de/2)**2)**3)))\n",
    "    return f0 -  (q*f0*Ljphi*n*L1/2)\n",
    "#     return L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,0.45,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,f_n_phi(x,0))\n",
    "plt.plot(x,f_n_phi(x,1))\n",
    "plt.plot(x,f_n_phi(x,2))\n",
    "plt.plot(x,f_n_phi(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,np.squeeze(np.diff((f_n_phi(x,1),f_n_phi(x,0)),axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
